{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from __future__ import annotations\n",
    "import re, os\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Tuple, List, Set, NewType, Optional, Iterable, TypeVar, Set\n",
    "import itertools\n",
    "\n",
    "import z3\n",
    "\n",
    "from oo_scoping.skill_classes import SkillPDDL, EffectTypePDDL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAS Parser\n",
    "\n",
    "[Docs](https://www.fast-downward.org/TranslatorOutputFormat#axiom) on FD translater output format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "5. **Convert to SkillPDDL etc representation**\n",
    "6. Skip sections with no contents, eg axiom\n",
    "\n",
    "Maybe todos:\n",
    "\n",
    "1. Test this on other sas files from the scoping repo\n",
    "2. Make it easier to access the index of varss. Maybe by storing those directly in `SasVar`, `SasVarVal`\n",
    "   1. z3 will treat vars as ints, so we should probably just store those directly and have a helper to get the string rep.\n",
    "3. Check that we aren't mishandling any optional bits. Eg we previously wrote a regex that couldn't handle operators with 0 prevail conditions\n",
    "4. Add n checks for anything where the sas file tells us how many there are. Or just check that input sas matches generated sas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions\n",
    "\n",
    "Do we reset each axiom variable to it's initial state at each timestep, and then evaluate the axiom rules? The _Evaluating axioms_ section suggests that, but the _Translator file format: Axiom section_ mentions using the current value of an affected var as a condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataclasses describing a SAS domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "# SasVarVal is just here for more explicit typing\n",
    "# Maybe it's wasted abstraction, idk\n",
    "\n",
    "\"\"\"\n",
    "MF: Should we have a dummy VarVal indicating that the value doesn't matter?\n",
    "I vote no for now. If we have that, may as well handle sets of vals, too.\n",
    "\"\"\"\n",
    "SasVarVal = NewType(\"SasVarVal\", str)\n",
    "\n",
    "@dataclass(frozen=True, order=True)\n",
    "class SasVar:\n",
    "    nm: str\n",
    "    axiom_layer: int\n",
    "    range: int\n",
    "    vals: Tuple[SasVarVal,...]\n",
    "\n",
    "    @staticmethod\n",
    "    def from_regex_tuple(m: Tuple[str, str, str, str]) -> SasVar:\n",
    "        return SasVar(m[0], int(m[1]), int(m[2]), SasVar.split_values(m[3]))\n",
    "\n",
    "    @staticmethod\n",
    "    def split_values(s: str) -> Tuple[SasVarVal, ...]:\n",
    "        return tuple([SasVarVal(x) for x in s.split(\"\\n\")])\n",
    "\n",
    "    def get_var_val_pair(self, i: int) -> SasVarValPair:\n",
    "        return SasVarValPair(self, i)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True, order=True)\n",
    "class SasVarValPair:\n",
    "    var: SasVar\n",
    "    # val: SasVarVal\n",
    "    val: int\n",
    "\n",
    "    @property\n",
    "    def val_nm(self) -> SasVarVal:\n",
    "        return self.var.vals[self.val]\n",
    "\n",
    "@dataclass(frozen=True, order=True)\n",
    "class SasEffect:\n",
    "    \"\"\"\n",
    "    Sas files distinguish between the condition on non-affected vars,\n",
    "    and the condition on the affected var.\n",
    "    Note that the var in condition_affected_var\n",
    "    and the var in result must be the same\n",
    "    It is maybe wasteful to keep it separate\n",
    "    \"\"\"\n",
    "    condition: Tuple[SasVarValPair,...]\n",
    "    affected_var: SasVar\n",
    "    affected_var_condition: Optional[int]\n",
    "    result_val: int\n",
    "\n",
    "    @property\n",
    "    def affected_var_condition_pair(self) -> Optional[SasVarValPair]:\n",
    "        if self.affected_var_condition is None:\n",
    "            return None\n",
    "        else:\n",
    "            return SasVarValPair(self.affected_var, self.affected_var_condition)\n",
    "\n",
    "    @property\n",
    "    def result_var_val_pair(self) -> SasVarValPair:\n",
    "        return SasVarValPair(self.affected_var, self.result_val)\n",
    "\n",
    "    @property\n",
    "    def full_condition(self) -> Tuple[SasVarValPair,...]:\n",
    "        \"\"\"\n",
    "        Combination of non-affected var condition\n",
    "        and affected var condition\n",
    "        MF: Should we sort by var? Nah.\n",
    "        \"\"\"\n",
    "        if self.affected_var_condition is None:\n",
    "            return self.condition\n",
    "        else:\n",
    "            return self.condition + [self.affected_var_condition_pair]\n",
    "\n",
    "\n",
    "@dataclass(frozen=True, order=True)\n",
    "class SasOperator:\n",
    "    nm: str\n",
    "    prevail: Tuple[SasVarValPair,...]\n",
    "    effects: Tuple[SasEffect,...]\n",
    "    cost: int = 1 #Default to 1, in case we don't use action cost\n",
    "\n",
    "\n",
    "\"\"\"An axiom is basically an effect that is applied every timestep, if applicable\"\"\"\n",
    "class SasAxiom(SasEffect):\n",
    "    pass\n",
    "\n",
    "@dataclass(frozen=True, order=True)\n",
    "class SasMutex:\n",
    "    facts: Tuple[SasVarValPair,...]\n",
    "\n",
    "\n",
    "@dataclass(frozen=True, order=True)\n",
    "class SasPartialState:\n",
    "    \"\"\"It would be nice to enforce uniqueness of keys\"\"\"\n",
    "    var_value_pairs: Tuple[SasVarValPair,...]\n",
    "\n",
    "    def __getitem__(self, key: SasVar) -> SasVarVal:\n",
    "        candidates = [x.val for x in self.var_value_pairs if x.var == key]\n",
    "        return candidates[0]\n",
    "\n",
    "\n",
    "class SasState(SasPartialState):\n",
    "    \"\"\"It would be nice to enforce full specification of vars\"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAS Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "T = TypeVar(\"T\")\n",
    "def powerset(iterable: Iterable[T]) -> Iterable[Tuple[T,...]]:\n",
    "    \"\"\"\n",
    "    powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\n",
    "    From https://docs.python.org/3/library/itertools.html#itertools-recipes\n",
    "    \"\"\"\n",
    "    s = list(iterable)\n",
    "    x = itertools.chain.from_iterable(itertools.combinations(s, r) for r in range(len(s)+1))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "\n",
    "\n",
    "from oo_scoping.downward_translate import sas_tasks as fd\n",
    "\n",
    "\n",
    "class SasParser:\n",
    "    \"\"\"\n",
    "    Parse sas planning files into python datastructures.\n",
    "    There are three sets of methods:\n",
    "\n",
    "    1. Parsing functions. One for each section, and one to string them together.\n",
    "    2. Helper functions\n",
    "    3. File writing functions\n",
    "    \"\"\"\n",
    "    # Regex patterns used in parsing\n",
    "    pattern_var_val_pair = \"(?P<var_num>\\d+) (?P<val_num>\\d+)\"\n",
    "    pattern_operator = \"begin_operator\\n(?P<nm>.+)\\n(?P<n_prevail>.+)\\n(?P<prevail>(\\d+ \\d+\\n)*?)(?P<n_effects>\\d+)\\n(?P<effects>[\\s\\S]+?)\\n(?P<cost>\\d+)\\nend_operator\"\n",
    "\n",
    "    # Type annotations for parsed values\n",
    "    s_sas: str\n",
    "    sas_vars: Tuple[SasVar, ...]\n",
    "    sas_operators: Tuple[SasOperator,...]\n",
    "    sas_mutexes: Tuple[SasMutex,...]\n",
    "    sas_axioms: Tuple[SasAxiom,...]\n",
    "    initial_state: SasState\n",
    "    goal: SasPartialState\n",
    "    _z3vars: Dict[SasVar, z3.Int]\n",
    "\n",
    "    def __init__(self, s_sas: Optional[str] = None, pth: Optional[str] = None) -> None:\n",
    "        \"\"\"\n",
    "        Specify either s_sas or pth.\n",
    "\n",
    "        \"\"\"\n",
    "        if s_sas is not None:\n",
    "            self.s_sas = s_sas\n",
    "        elif pth is not None:\n",
    "            with open(pth, \"r\") as f:\n",
    "                self.s_sas = f.read()\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Please specify either s_sas or the pth of the sas file when creating a SasParser.\"\n",
    "            )\n",
    "        self._z3vars: Dict[SasVar, z3.Int] = dict()\n",
    "\n",
    "    # Parsing functions\n",
    "    def parse(self):\n",
    "        \"\"\"Do entire parsing\"\"\"\n",
    "        self.parse_version()\n",
    "        self.parse_metric()\n",
    "        self.parse_vars()\n",
    "        self.parse_mutex()\n",
    "        self.parse_initial_state()\n",
    "        self.parse_goal()\n",
    "        self.parse_axioms()\n",
    "        self.parse_operators()\n",
    "\n",
    "\n",
    "    def parse_version(self) -> str:\n",
    "        pattern_version = \"begin_version\\n(?P<version>\\d+)\\nend_version\"\n",
    "        versions = re.findall(pattern_version, self.s_sas)\n",
    "        if len(versions) != 1:\n",
    "            raise ValueError(f\"File specifies {len(versions)} versions. It should specify 1.\")\n",
    "        self.version = versions[0][0]\n",
    "        return self.version\n",
    "\n",
    "    def parse_metric(self) -> int:\n",
    "        \"\"\"The metric should be 0 or 1\"\"\"\n",
    "        pattern_metric = \"begin_metric\\n(?P<version>\\d+)\\nend_metric\"\n",
    "        metrics = re.findall(pattern_metric, self.s_sas)\n",
    "        if len(metrics) != 1:\n",
    "            raise ValueError(f\"File specifies {len(metrics)} metrics. It should specify 1.\")\n",
    "        self.metric = int(metrics[0][0])\n",
    "        return self.metric\n",
    "\n",
    "\n",
    "    def parse_vars(self) -> Tuple[SasVar, ...]:\n",
    "        # Regex notes: [\\s\\S] matches all characters, including newlines\n",
    "        # Putting ? after a quantifier makes it non-greedy, so that it stops as soon as it can\n",
    "        var_pattern = \"begin_variable\\n(?P<nm>.*)\\n(?P<axiom_layer>.*)\\n(?P<range>.*)\\n(?P<vals>[\\s\\S]*?)\\nend_variable\"\n",
    "        # TODO use finditer instead, so that we can use named capture groups.\n",
    "        # Less error prone, more clear\n",
    "        matches = re.findall(var_pattern, self.s_sas)\n",
    "        sas_vars: List[SasVar] = []\n",
    "        for m in matches:\n",
    "            sas_vars.append(SasVar.from_regex_tuple(m))\n",
    "        sas_vars = tuple(sas_vars)\n",
    "        self.sas_vars = sas_vars\n",
    "        return sas_vars\n",
    "\n",
    "    def parse_mutex(self) -> Tuple[SasMutex,...]:\n",
    "        \"\"\"\n",
    "        Must be run after parse_vars\n",
    "        \"\"\"\n",
    "        mutex_pattern = (\n",
    "            \"begin_mutex_group\\n(?P<n_facts>\\d+)\\n(?P<facts>[\\s\\S]*?)\\nend_mutex_group\"\n",
    "        )\n",
    "        mutexes_lst: List[SasMutex] = []\n",
    "\n",
    "        for mutex_group_match in re.finditer(mutex_pattern, self.s_sas):\n",
    "            facts_lst: List[SasVarValPair] = []\n",
    "            facts_strs = mutex_group_match.group(\"facts\").splitlines()\n",
    "            for fs in facts_strs:\n",
    "                fact = self.get_sas_var_val_pair_from_str(fs)\n",
    "                facts_lst.append(fact)\n",
    "            mutex = SasMutex(tuple(facts_lst))\n",
    "            mutexes_lst.append(mutex)\n",
    "\n",
    "        mutexes = tuple(mutexes_lst)\n",
    "        self.mutexes = mutexes\n",
    "        return mutexes\n",
    "\n",
    "    def parse_initial_state(self) -> SasState:\n",
    "        pattern_initial_state = \"begin_state\\n(?P<state>[\\s\\S]+?)\\nend_state\"\n",
    "        s_state = re.search(pattern_initial_state, self.s_sas).group(\"state\")\n",
    "        vals = s_state.splitlines()\n",
    "        assert len(vals) == len(self.sas_vars)\n",
    "        var_val_pairs = tuple([self.sas_vars[i].get_var_val_pair(int(vals[i])) for i in range(len(vals))])\n",
    "        self.initial_state = SasState(var_val_pairs)\n",
    "        return self.initial_state\n",
    "\n",
    "    def parse_goal(self) -> SasPartialState:\n",
    "        pattern_goal = \"begin_goal\\n(?P<n>\\d+)\\n(?P<var_vals>[\\s\\S]+?)\\nend_goal\"\n",
    "        s_goal = re.search(pattern_goal, self.s_sas).group(\"var_vals\")\n",
    "        var_val_strs = s_goal.splitlines()\n",
    "        var_val_pairs = tuple([self.get_sas_var_val_pair_from_str(s) for s in var_val_strs])\n",
    "        self.goal = SasPartialState(var_val_pairs)\n",
    "        return self.goal\n",
    "\n",
    "    def parse_axioms(self) -> Tuple[SasAxiom,...]:\n",
    "        pattern_head = \"(?P<var_num>\\d+) (?P<val_num_old>\\d+) (?P<val_num_new>\\d+)\"\n",
    "        pattern_axiom = f\"begin_rule\\n(?P<n>\\d+)\\n(?P<conditions>[\\s\\S]+?)\\n{pattern_head}\\nend_rule\"\n",
    "        axioms_lst: List[SasAxiom] = []\n",
    "        for m_axiom in re.finditer(pattern_axiom, self.s_sas):\n",
    "            conds_strs = m_axiom.group(\"conditions\").splitlines()\n",
    "            conds = [self.get_sas_var_val_pair_from_str(c) for c in conds_strs]\n",
    "            i_affected_var = int(m_axiom.group(\"var_num\"))\n",
    "            i_val_old = int(m_axiom.group(\"val_num_old\"))\n",
    "            i_val_new = int(m_axiom.group(\"val_num_new\"))\n",
    "            affected_var = self.sas_vars[i_affected_var]\n",
    "            axioms_lst.append(\n",
    "                SasAxiom(\n",
    "                    condition=tuple(conds),\n",
    "                    affected_var=affected_var,\n",
    "                    affected_var_condition=affected_var.vals[i_val_old],\n",
    "                    result_val=affected_var.vals[i_val_new],\n",
    "                )\n",
    "            )\n",
    "        self.axioms = tuple(axioms_lst)\n",
    "        return self.axioms\n",
    "\n",
    "\n",
    "    def parse_operators(self) -> Tuple[SasOperator,...]:\n",
    "        pattern_operator_count = \"end_goal\\n(?P<n>\\d+)\\nbegin_operator\"\n",
    "        n_operators = int(re.search(pattern_operator_count, self.s_sas).group(\"n\"))\n",
    "\n",
    "        operators: List[SasOperator] = []\n",
    "        for m in re.finditer(SasParser.pattern_operator, self.s_sas):\n",
    "            prevail_lines = m.group(\"prevail\").splitlines()\n",
    "            prevail = tuple([self.get_sas_var_val_pair_from_str(x) for x in prevail_lines])\n",
    "            effect_lines = m.group(\"effects\").splitlines()\n",
    "            effects = tuple([self.parse_effect(x) for x in effect_lines])\n",
    "            operators.append(SasOperator(\n",
    "                nm = m.group(\"nm\"),\n",
    "                prevail = prevail,\n",
    "                effects=effects,\n",
    "                cost=m.group(\"cost\")\n",
    "\n",
    "            ))\n",
    "        if len(operators) != n_operators:\n",
    "            raise ValueError(f\"The sas file claims to have {n_operators} operators, but we found {len(operators)}\")\n",
    "        self.operators = tuple(operators)\n",
    "        return self.operators\n",
    "\n",
    "    def parse_effect(self, s: str) -> SasEffect:\n",
    "        # n_cond = int(re.match(\"(?P<n_cond>\\d+).+\", s).group(\"n_cond\"))\n",
    "        s_split = s.split(\" \")\n",
    "        n_cond = int(s_split[0])\n",
    "\n",
    "        conds: List[SasVarValPair] = []\n",
    "        i_conds_start = 1\n",
    "        for i_pair in range(n_cond):\n",
    "            num_var = int(s_split[i_conds_start + i_pair*2])\n",
    "            num_val = int(s_split[i_conds_start + (i_pair*2) + 1])\n",
    "            conds.append(self.get_sas_var_val_pair_from_ints(num_var, num_val))\n",
    "\n",
    "        i_conds_end = i_conds_start + n_cond * 2\n",
    "        num_var_affected = int(s_split[i_conds_end])\n",
    "        var_affected = self.sas_vars[num_var_affected]\n",
    "        num_val_cond = int(s_split[i_conds_end + 1])\n",
    "        # -1 means that there is no condition on the affected var\n",
    "        if num_val_cond == -1:\n",
    "            val_cond = None\n",
    "        else:\n",
    "            val_cond = var_affected.vals[num_val_cond]\n",
    "\n",
    "        num_val_result = int(s_split[i_conds_end + 2])\n",
    "        if i_conds_end + 2 != len(s_split) - 1:\n",
    "            raise ValueError(\"We miscounted\")\n",
    "\n",
    "        return SasEffect(\n",
    "            condition=tuple(conds),\n",
    "            affected_var=var_affected,\n",
    "            affected_var_condition=val_cond,\n",
    "            result_val=num_val_result\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Helper functions\n",
    "    ## Getting SasVarValPairs\n",
    "    def get_sas_var_val_pair_from_ints(\n",
    "        self, var_num: int, val_num: int\n",
    "    ) -> SasVarValPair:\n",
    "        var0 = self.sas_vars[var_num]\n",
    "        # val0 = var0.vals[val_num]\n",
    "        return SasVarValPair(var0, val_num)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_var_val_nums_from_str(s: str) -> Tuple[int, int]:\n",
    "        m = re.match(SasParser.pattern_var_val_pair, s)\n",
    "        if m is None:\n",
    "            raise ValueError(f\"The string is not a pair of ints:\\n{s}\")\n",
    "        var_num = int(m.group(\"var_num\"))\n",
    "        val_num = int(m.group(\"val_num\"))\n",
    "        return var_num, val_num\n",
    "\n",
    "    def get_sas_var_val_pair_from_str(self, s: str) -> SasVarValPair:\n",
    "        var_num, val_num = SasParser.get_var_val_nums_from_str(s)\n",
    "        return self.get_sas_var_val_pair_from_ints(var_num, val_num)\n",
    "\n",
    "\n",
    "    def var_val_pair2ints(self, p: SasVarValPair) -> Tuple[int, int]:\n",
    "        \"\"\"Returns the pair of ints a sas file would use to represent p\"\"\"\n",
    "        i_var = self.sas_vars.index(p.var)\n",
    "        # i_val = p.var.vals.index(p.val)\n",
    "        return (i_var, p.val)\n",
    "\n",
    "    def var_val_pair2sas_str(self, p: SasVarValPair) -> str:\n",
    "        return \" \".join(map(str, self.var_val_pair2ints(p)))\n",
    "\n",
    "    # Writing back to SAS\n",
    "    def generate_sas(self) -> str:\n",
    "        pieces: List[str] = [\n",
    "            self.generate_version_and_metric_sections(),\n",
    "            self.generate_variables_section(),\n",
    "            self.generate_mutexes_section(),\n",
    "            self.generate_initial_state_section(),\n",
    "            self.generate_goal_section(),\n",
    "            self.generate_operators_section(),\n",
    "            self.generate_axioms_section()\n",
    "        ]\n",
    "        return \"\\n\".join(pieces) + \"\\n\"\n",
    "\n",
    "\n",
    "    def generate_version_and_metric_sections(self) -> str:\n",
    "        return f\"begin_version\\n{self.version}\\nend_version\\nbegin_metric\\n{self.metric}\\nend_metric\"\n",
    "\n",
    "    ## Variables\n",
    "    def generate_variables_section(self) -> str:\n",
    "        pieces: List[str] = [str(len(self.sas_vars))]\n",
    "        for v in self.sas_vars:\n",
    "            pieces.append(self.generate_variable_str(v))\n",
    "        return \"\\n\".join(pieces)\n",
    "\n",
    "    def generate_variable_str(self, v: SasVar) -> str:\n",
    "        pieces: List[str] = [\n",
    "            \"begin_variable\",\n",
    "            v.nm,\n",
    "            str(v.axiom_layer),\n",
    "            str(v.range)\n",
    "        ]\n",
    "        for val in v.vals:\n",
    "            pieces.append(val)\n",
    "        pieces.append(\"end_variable\")\n",
    "        return \"\\n\".join(pieces)\n",
    "\n",
    "    ## Mutexes\n",
    "    def generate_mutexes_section(self) -> str:\n",
    "        pieces: List[str] = [str(len(self.mutexes))]\n",
    "        pieces.extend([self.generate_mutex_str(m) for m in self.mutexes])\n",
    "        return \"\\n\".join(pieces)\n",
    "\n",
    "    def generate_mutex_str(self, m: SasMutex) -> str:\n",
    "        pieces: List[str] = [\"begin_mutex_group\"]\n",
    "        pieces.append(str(len(m.facts)))\n",
    "        # raise NotImplementedError\n",
    "        for f in m.facts:\n",
    "            i_var = self.sas_vars.index(f.var)\n",
    "            # i_val = f.var.vals.index(f.val)\n",
    "            pieces.append(f\"{i_var} {f.val}\")\n",
    "        pieces.append(\"end_mutex_group\")\n",
    "        return \"\\n\".join(pieces)\n",
    "\n",
    "    ## Initial State\n",
    "    def generate_initial_state_section(self) -> str:\n",
    "        pieces: List[str] = [\"begin_state\"]\n",
    "        # pieces.extend([self.var_val_pair2sas_str(p) for p in self.initial_state.var_value_pairs])\n",
    "        pieces.extend([str(p.val) for p in self.initial_state.var_value_pairs])\n",
    "        pieces.append(\"end_state\")\n",
    "        return \"\\n\".join(pieces)\n",
    "\n",
    "    ## Goals\n",
    "    def generate_goal_section(self) -> str:\n",
    "        pieces: List[str] = [\"begin_goal\", str(len(self.goal.var_value_pairs))]\n",
    "        pieces.extend([self.var_val_pair2sas_str(p) for p in self.goal.var_value_pairs])\n",
    "        pieces.append(\"end_goal\")\n",
    "        return \"\\n\".join(pieces)\n",
    "\n",
    "    def generate_operators_section(self) -> str:\n",
    "        pieces: List[str] = [str(len(self.operators))]\n",
    "        pieces.extend([self.generate_operator_str(o) for o in self.operators])\n",
    "        return \"\\n\".join(pieces)\n",
    "\n",
    "    ## Operators\n",
    "    def generate_operator_str(self, o: SasOperator) -> str:\n",
    "        pieces: List[str] = [\n",
    "            \"begin_operator\",\n",
    "            o.nm,\n",
    "            str(len(o.prevail))\n",
    "        ]\n",
    "        # Add prevail conditions\n",
    "        pieces.extend([self.var_val_pair2sas_str(p) for p in o.prevail])\n",
    "\n",
    "        # Add effects\n",
    "        pieces.append(str(len(o.effects)))\n",
    "        pieces.extend([self.effect2sas_str(e) for e in o.effects])\n",
    "\n",
    "        # Add cost\n",
    "        pieces.append(str(o.cost))\n",
    "        pieces.append(\"end_operator\")\n",
    "        return \"\\n\".join(pieces)\n",
    "\n",
    "\n",
    "    def effect2sas_str(self, e: SasEffect) -> str:\n",
    "        pieces: List[str] = [str(len(e.condition))]\n",
    "        # Effect conditions\n",
    "        pieces.extend([self.var_val_pair2sas_str(p) for p in e.condition])\n",
    "        # Affected var\n",
    "        pieces.append(str(self.sas_vars.index(e.affected_var)))\n",
    "        # Affected var condition\n",
    "        if e.affected_var_condition is None:\n",
    "            pieces.append(\"-1\")\n",
    "        else:\n",
    "            pieces.append(str(e.affected_var.vals.index(e.affected_var_condition)))\n",
    "        # Result value\n",
    "        pieces.append(str(e.result_val))\n",
    "        return \" \".join(pieces)\n",
    "\n",
    "    ## Axioms\n",
    "    def generate_axioms_section(self) -> str:\n",
    "        pieces: List[str] = [str(len(self.axioms))]\n",
    "        pieces.extend([self.axiom2sas_str(a) for a in self.axioms])\n",
    "        return \"\\n\".join(pieces)\n",
    "\n",
    "    def axiom2sas_str(self, a: SasAxiom) -> str:\n",
    "        pieces: List[str] = [\"begin_rule\", str(len(a.condition))]\n",
    "        # Conditions\n",
    "        pieces.extend([self.var_val_pair2sas_str(p) for p in a.condition])\n",
    "        # Affected var\n",
    "        i_var = self.sas_vars.index(a.affected_var)\n",
    "        # i_val_old = a.affected_var.vals.index(a.affected_var_condition)\n",
    "        # i_val_new = a.affected_var.vals.index(a.result_val)\n",
    "        pieces.append(f\"{i_var} {a.affected_var_condition} {a.result_val}\")\n",
    "        pieces.append(\"end_rule\")\n",
    "        return \"\\n\".join(pieces)\n",
    "\n",
    "    # Check parse\n",
    "    def check_parse(self) -> bool:\n",
    "        return self.generate_sas() == self.s_sas\n",
    "\n",
    "\n",
    "    # Converting to scopeable representation\n",
    "    def z3var(self, v: SasVar) -> z3.Int:\n",
    "        \"\"\"\n",
    "        Get the z3 var for a SasVar\n",
    "        \"\"\"\n",
    "        if v in self._z3vars.keys():\n",
    "            self._z3vars[v.nm] = z3.Int(v.nm)\n",
    "        return self._z3vars[v.nm]\n",
    "\n",
    "    def effect_type(self, p: SasVarValPair) -> EffectTypePDDL:\n",
    "        return EffectTypePDDL(pvar=self.z3var(p.var), index=p.val)\n",
    "\n",
    "    def varvalpair2condition(self, p: SasVarValPair) -> z3.BoolRef:\n",
    "        return self.z3var(p.var) == p.val\n",
    "\n",
    "    def sasoperator2skill(self, a: SasOperator) -> SkillPDDL:\n",
    "        # Start with prevail conditions and effect preconditions\n",
    "        preconditions = list(a.prevail)\n",
    "        for effect in a.effects:\n",
    "            if effect.affected_var_condition is not None and effect.affected_var_condition != -1:\n",
    "                preconditions.append(effect.affected_var_condition_pair)\n",
    "\n",
    "        # Add mutex-derived preconditions\n",
    "        for mutex in self.sas_mutexes:\n",
    "            for pair in mutex.facts:\n",
    "                if pair in preconditions:\n",
    "                    # For each other pair in the mutex group, add a precondition that it's not true\n",
    "                    other_pairs = [p for p in mutex.facts if p != pair]\n",
    "                    for other_pair in other_pairs:\n",
    "                        # Here we add a precondition to ensure the other pairs are not true\n",
    "                        preconditions.append(self.negate_condition(other_pair))\n",
    "\n",
    "        # Convert preconditions to z3.ExprRef\n",
    "        precondition_expr = z3.And(*[self.varvalpair2condition(p) for p in preconditions])\n",
    "\n",
    "        # Convert effects to EffectTypePDDL\n",
    "        effects = []\n",
    "        for effect in a.effects:\n",
    "            affected_var_str = effect.result_var_val_pair.var.nm\n",
    "            index = effect.result_var_val_pair.val  # The index in the SasVar.vals list\n",
    "            pvar = z3.Bool(affected_var_str)\n",
    "            effect_pddl = EffectTypePDDL(pvar=pvar, index=index)\n",
    "            effects.append(effect_pddl)\n",
    "\n",
    "        # Create the SkillPDDL\n",
    "        action_name = a.nm\n",
    "        skill = SkillPDDL(precondition=precondition_expr, action=action_name, effects=effects)\n",
    "\n",
    "        return skill\n",
    "\n",
    "    def negate_condition(self, pair: SasVarValPair) -> z3.ExprRef:\n",
    "        return z3.Not(self.varvalpair2condition(pair))\n",
    "\n",
    "    def scope(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "z3.z3.BoolRef"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(z3.Int(\"x\") == 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pre_extension(s: str, s_suffix: str) -> str:\n",
    "    s_split = s.split(\".\")\n",
    "    s_split = s_split[:-1] + [s_suffix] + s_split[-1:]\n",
    "    return \".\".join(s_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing...\n",
      "Parsing: [0.000s CPU, 0.005s wall-clock]\n",
      "Normalizing task... [0.000s CPU, 0.002s wall-clock]\n",
      "Instantiating...\n",
      "Generating Datalog program... [0.000s CPU, 0.006s wall-clock]\n",
      "Normalizing Datalog program...\n",
      "Normalizing Datalog program: [0.000s CPU, 0.003s wall-clock]\n",
      "Preparing model... [0.000s CPU, 0.003s wall-clock]\n",
      "Generated 45 rules.\n",
      "Computing model... [0.010s CPU, 0.012s wall-clock]\n",
      "331 relevant atoms\n",
      "258 auxiliary atoms\n",
      "589 final queue length\n",
      "1039 total queue pushes\n",
      "Completing instantiation... [0.010s CPU, 0.017s wall-clock]\n",
      "Instantiating: [0.020s CPU, 0.043s wall-clock]\n",
      "Computing fact groups...\n",
      "Finding invariants...\n",
      "13 initial candidates\n",
      "Finding invariants: [0.000s CPU, 0.005s wall-clock]\n",
      "Checking invariant weight... [0.000s CPU, 0.000s wall-clock]\n",
      "Instantiating groups... [0.000s CPU, 0.001s wall-clock]\n",
      "Collecting mutex groups... [0.000s CPU, 0.001s wall-clock]\n",
      "Choosing groups...\n",
      "0 uncovered facts\n",
      "Choosing groups: [0.000s CPU, 0.001s wall-clock]\n",
      "Building translation key... [0.000s CPU, 0.000s wall-clock]\n",
      "Computing fact groups: [0.000s CPU, 0.010s wall-clock]\n",
      "Building STRIPS to SAS dictionary... [0.000s CPU, 0.000s wall-clock]\n",
      "Building dictionary for full mutex groups... [0.000s CPU, 0.000s wall-clock]\n",
      "Building mutex information...\n",
      "Building mutex information: [0.000s CPU, 0.000s wall-clock]\n",
      "Translating task...\n",
      "Processing axioms...\n",
      "Simplifying axioms... [0.000s CPU, 0.000s wall-clock]\n",
      "Processing axioms: [0.000s CPU, 0.001s wall-clock]\n",
      "Translating task: [0.010s CPU, 0.010s wall-clock]\n",
      "0 effect conditions simplified\n",
      "0 implied preconditions added\n",
      "Detecting unreachable propositions...\n",
      "0 operators removed\n",
      "0 axioms removed\n",
      "10 propositions removed\n",
      "Detecting unreachable propositions: [0.010s CPU, 0.010s wall-clock]\n",
      "Reordering and filtering variables...\n",
      "20 of 20 variables necessary.\n",
      "10 of 20 mutex groups necessary.\n",
      "208 of 208 operators necessary.\n",
      "0 of 0 axiom rules necessary.\n",
      "Reordering and filtering variables: [0.000s CPU, 0.004s wall-clock]\n",
      "Translator variables: 20\n",
      "Translator derived variables: 0\n",
      "Translator facts: 68\n",
      "Translator goal facts: 10\n",
      "Translator mutex groups: 10\n",
      "Translator total mutex groups size: 40\n",
      "Translator operators: 208\n",
      "Translator axioms: 0\n",
      "Translator task size: 1354\n",
      "warning: could not determine peak memory\n",
      "Writing output SAS file... [0.000s CPU, 0.002s wall-clock]\n",
      "Done grounding! Starting to scope.\n",
      "Done Scoping!\n",
      "Done! [0.550s CPU, 2.075s wall-clock]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_root = \"../../..\"\n",
    "# pth = \"../../../gripper-painting.sas\"\n",
    "pth_sas_dir = f\"{repo_root}/generated_sas\"\n",
    "os.makedirs(pth_sas_dir, exist_ok=True)\n",
    "pth_sas_in = f\"{pth_sas_dir}/gripper-painting.sas\"\n",
    "cmd_s = f\"python {repo_root}/oo_scoping/downward_translate/translate_and_scope.py {repo_root}/examples/gripper-painting-domain/domain.pddl {repo_root}/examples/gripper-painting-domain/prob04.pddl --sas-file {pth_sas_in} --scope True\"\n",
    "os.system(cmd_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parser = SasParser(pth=pth_sas_in)\n",
    "parser.parse()\n",
    "\n",
    "s_sas_out = parser.generate_sas()\n",
    "with open(add_pre_extension(pth_sas_in, \"regen\"), \"w\") as f:\n",
    "    f.write(s_sas_out)\n",
    "\n",
    "print(s_sas_out == parser.s_sas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 ('scoping')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7dd683c898c07e6a957de82605f0773a32c40ae55c81e411f07fe5e690bcc0f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
